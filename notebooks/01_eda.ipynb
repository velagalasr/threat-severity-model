{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3526315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from data_loader import NSLKDDDataLoader\n",
    "from config import ATTACK_CATEGORY_MAP, COLUMN_NAMES\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6bca5",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "We'll load the NSL-KDD dataset using our custom data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd261e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = NSLKDDDataLoader()\n",
    "\n",
    "# Load and preprocess data\n",
    "print(\"Loading NSL-KDD dataset...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = loader.load_and_preprocess()\n",
    "\n",
    "print(f\"\\n✓ Data loaded successfully!\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Validation samples: {len(X_val):,}\")\n",
    "print(f\"Test samples: {len(X_test):,}\")\n",
    "print(f\"Total features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72032bfc",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis\n",
    "\n",
    "Understanding the distribution of threat severity scores is critical for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ecdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all sets for comprehensive analysis\n",
    "y_all = pd.concat([y_train, y_val, y_test])\n",
    "\n",
    "# Plot threat severity distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(y_all, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Threat Severity Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Threat Severity Scores')\n",
    "axes[0].axvline(y_all.mean(), color='red', linestyle='--', label=f'Mean: {y_all.mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(y_all, vert=True)\n",
    "axes[1].set_ylabel('Threat Severity Score')\n",
    "axes[1].set_title('Box Plot of Threat Severity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nThreat Severity Statistics:\")\n",
    "print(y_all.describe())\n",
    "print(f\"\\nValue Counts:\")\n",
    "print(y_all.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076bd78",
   "metadata": {},
   "source": [
    "## 3. Feature Statistics\n",
    "\n",
    "Let's examine the statistical properties of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d260557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features\n",
    "X_all = pd.concat([X_train, X_val, X_test])\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Feature Statistics (first 10 features):\")\n",
    "print(X_all.iloc[:, :10].describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing = X_all.isnull().sum()\n",
    "if missing.any():\n",
    "    print(f\"\\nMissing values found:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"\\n✓ No missing values detected\")\n",
    "\n",
    "# Data types\n",
    "print(f\"\\nData types:\")\n",
    "print(X_all.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071033e",
   "metadata": {},
   "source": [
    "## 4. Attack vs Normal Traffic Analysis\n",
    "\n",
    "Compare characteristics of normal traffic vs attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary labels\n",
    "is_attack = (y_all > 0).astype(int)\n",
    "\n",
    "# Count distribution\n",
    "attack_counts = is_attack.value_counts()\n",
    "print(\"Traffic Distribution:\")\n",
    "print(f\"Normal: {attack_counts[0]:,} ({100*attack_counts[0]/len(is_attack):.1f}%)\")\n",
    "print(f\"Attack: {attack_counts[1]:,} ({100*attack_counts[1]/len(is_attack):.1f}%)\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "ax.pie(attack_counts.values, labels=['Normal', 'Attack'], autopct='%1.1f%%', \n",
    "       colors=colors, startangle=90)\n",
    "ax.set_title('Normal vs Attack Traffic Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce5e37",
   "metadata": {},
   "source": [
    "## 5. Feature Correlations\n",
    "\n",
    "Identify highly correlated features that might impact threat severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4449969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with target\n",
    "feature_target_corr = pd.DataFrame({\n",
    "    'feature': X_all.columns,\n",
    "    'correlation': [X_all[col].corr(y_all) for col in X_all.columns]\n",
    "})\n",
    "feature_target_corr['abs_correlation'] = feature_target_corr['correlation'].abs()\n",
    "feature_target_corr = feature_target_corr.sort_values('abs_correlation', ascending=False)\n",
    "\n",
    "# Plot top 15 correlated features\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = feature_target_corr.head(15)\n",
    "ax.barh(range(len(top_features)), top_features['correlation'])\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('Correlation with Threat Severity')\n",
    "ax.set_title('Top 15 Features Correlated with Threat Severity')\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features by Correlation:\")\n",
    "print(feature_target_corr.head(10)[['feature', 'correlation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d2edf",
   "metadata": {},
   "source": [
    "## 6. Feature Distributions\n",
    "\n",
    "Visualize distributions of key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8176147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top correlated features\n",
    "top_6_features = feature_target_corr.head(6)['feature'].tolist()\n",
    "\n",
    "# Plot distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_6_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Separate by attack vs normal\n",
    "    normal_data = X_all.loc[is_attack == 0, feature]\n",
    "    attack_data = X_all.loc[is_attack == 1, feature]\n",
    "    \n",
    "    # Plot histograms\n",
    "    ax.hist(normal_data, bins=30, alpha=0.5, label='Normal', color='#2ecc71')\n",
    "    ax.hist(attack_data, bins=30, alpha=0.5, label='Attack', color='#e74c3c')\n",
    "    \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Distribution: {feature}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a1a30f",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Conclusions\n",
    "\n",
    "### Findings:\n",
    "\n",
    "1. **Class Imbalance**: The dataset shows imbalance between normal and attack traffic\n",
    "   - This will require careful handling during model training (e.g., class weights)\n",
    "\n",
    "2. **Feature Correlations**: Several features show strong correlation with threat severity\n",
    "   - These will be important for model predictions\n",
    "   - Feature engineering can create additional informative features\n",
    "\n",
    "3. **Feature Distributions**: Attack traffic shows distinct patterns compared to normal\n",
    "   - Clear separation in key features enables effective classification\n",
    "   - Some features show multimodal distributions\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Engineer domain-specific security features (notebook 02)\n",
    "2. Train multiple models and compare performance (notebook 03)\n",
    "3. Optimize thresholds for different operational SLOs (notebook 06)\n",
    "4. Deploy production-ready model with monitoring\n",
    "\n",
    "### Model Training Considerations:\n",
    "\n",
    "- Use stratified sampling to handle class imbalance\n",
    "- Apply feature scaling for gradient-based models\n",
    "- Consider ensemble methods (XGBoost, LightGBM)\n",
    "- Implement SHAP for explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daaf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for next notebooks\n",
    "print(\"\\n✓ EDA complete!\")\n",
    "print(f\"\\nDataset ready for model training:\")\n",
    "print(f\"  - Features: {X_train.shape[1]}\")\n",
    "print(f\"  - Training samples: {len(X_train):,}\")\n",
    "print(f\"  - Class balance: {100*attack_counts[1]/(attack_counts[0]+attack_counts[1]):.1f}% attacks\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
